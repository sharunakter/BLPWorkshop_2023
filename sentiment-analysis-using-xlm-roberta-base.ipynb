{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-02T18:36:52.796248Z","iopub.execute_input":"2023-09-02T18:36:52.796667Z","iopub.status.idle":"2023-09-02T18:36:52.810000Z","shell.execute_reply.started":"2023-09-02T18:36:52.796636Z","shell.execute_reply":"2023-09-02T18:36:52.808863Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"!pip install transformers\n!pip install datasets\n!pip install evaluate\n!pip install --upgrade accelerate","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:36:52.814675Z","iopub.execute_input":"2023-09-02T18:36:52.815028Z","iopub.status.idle":"2023-09-02T18:37:43.996203Z","shell.execute_reply.started":"2023-09-02T18:36:52.814997Z","shell.execute_reply":"2023-09-02T18:37:43.994878Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.32.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.0)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.23.5)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.0.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.6.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.22.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import logging\nimport os\nimport random\nimport sys\nfrom dataclasses import dataclass, field\nfrom typing import Optional\nimport pandas as pd\nimport datasets\nimport evaluate\nimport numpy as np\nfrom datasets import load_dataset, Dataset, DatasetDict\nimport torch\n\nimport transformers\nfrom transformers import (\n    AutoConfig,\n    AutoModelForSequenceClassification,\n    AutoTokenizer,\n    DataCollatorWithPadding,\n    EvalPrediction,\n    HfArgumentParser,\n    PretrainedConfig,\n    Trainer,\n    TrainingArguments,\n    default_data_collator,\n    set_seed,\n)\nfrom transformers.trainer_utils import get_last_checkpoint\nfrom transformers.utils import check_min_version, send_example_telemetry\nfrom transformers.utils.versions import require_version\n\n\nlogger = logging.getLogger(__name__)\n\nlogging.basicConfig(\n    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n    datefmt=\"%m/%d/%Y %H:%M:%S\",\n    handlers=[logging.StreamHandler(sys.stdout)],\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:44.000244Z","iopub.execute_input":"2023-09-02T18:37:44.003288Z","iopub.status.idle":"2023-09-02T18:37:44.018741Z","shell.execute_reply.started":"2023-09-02T18:37:44.003241Z","shell.execute_reply":"2023-09-02T18:37:44.017604Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"!wget \"https://raw.githubusercontent.com/DeepProgram/random/main/blp23_sentiment_test_with_label.tsv\"","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:44.023960Z","iopub.execute_input":"2023-09-02T18:37:44.024788Z","iopub.status.idle":"2023-09-02T18:37:45.280512Z","shell.execute_reply.started":"2023-09-02T18:37:44.024753Z","shell.execute_reply":"2023-09-02T18:37:45.279358Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n--2023-09-02 18:37:45--  https://raw.githubusercontent.com/DeepProgram/random/main/blp23_sentiment_test_with_label.tsv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1626269 (1.6M) [text/plain]\nSaving to: ‘blp23_sentiment_test_with_label.tsv.1’\n\nblp23_sentiment_tes 100%[===================>]   1.55M  --.-KB/s    in 0.07s   \n\n2023-09-02 18:37:45 (22.1 MB/s) - ‘blp23_sentiment_test_with_label.tsv.1’ saved [1626269/1626269]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!wget \"https://raw.githubusercontent.com/DeepProgram/random/main/sentiment_analysis_data.zip\"","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:45.284339Z","iopub.execute_input":"2023-09-02T18:37:45.290013Z","iopub.status.idle":"2023-09-02T18:37:46.509801Z","shell.execute_reply.started":"2023-09-02T18:37:45.289964Z","shell.execute_reply":"2023-09-02T18:37:46.508493Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n--2023-09-02 18:37:46--  https://raw.githubusercontent.com/DeepProgram/random/main/sentiment_analysis_data.zip\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2645403 (2.5M) [application/zip]\nSaving to: ‘sentiment_analysis_data.zip.1’\n\nsentiment_analysis_ 100%[===================>]   2.52M  --.-KB/s    in 0.08s   \n\n2023-09-02 18:37:46 (31.8 MB/s) - ‘sentiment_analysis_data.zip.1’ saved [2645403/2645403]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!unzip -o /kaggle/working/sentiment_analysis_data.zip","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:46.512252Z","iopub.execute_input":"2023-09-02T18:37:46.512991Z","iopub.status.idle":"2023-09-02T18:37:47.684704Z","shell.execute_reply.started":"2023-09-02T18:37:46.512945Z","shell.execute_reply":"2023-09-02T18:37:47.683432Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nArchive:  /kaggle/working/sentiment_analysis_data.zip\n  inflating: blp23_sentiment_dev_test.tsv  \n  inflating: blp23_sentiment_dev.tsv  \n  inflating: blp23_sentiment_train.tsv  \n","output_type":"stream"}]},{"cell_type":"code","source":"train_file = '/kaggle/working/blp23_sentiment_train.tsv'\nvalidation_file = '/kaggle/working/blp23_sentiment_dev.tsv'\ntest_file = '/kaggle/working/blp23_sentiment_dev_test.tsv'","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:47.686768Z","iopub.execute_input":"2023-09-02T18:37:47.690579Z","iopub.status.idle":"2023-09-02T18:37:47.701270Z","shell.execute_reply.started":"2023-09-02T18:37:47.690534Z","shell.execute_reply":"2023-09-02T18:37:47.700244Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    learning_rate=2e-5,\n    num_train_epochs=1,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    output_dir=\"./bertBaseMultilingualNew/\",\n    overwrite_output_dir=True,\n    remove_unused_columns=False,\n    local_rank= 1,\n    load_best_model_at_end=True,\n    save_total_limit=2,\n    save_strategy=\"no\"\n)\n\nmax_train_samples = None\nmax_eval_samples=None\nmax_predict_samples=None\nmax_seq_length = 512\nbatch_size = 16","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:47.703179Z","iopub.execute_input":"2023-09-02T18:37:47.703919Z","iopub.status.idle":"2023-09-02T18:37:47.727512Z","shell.execute_reply.started":"2023-09-02T18:37:47.703883Z","shell.execute_reply":"2023-09-02T18:37:47.726500Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stderr","text":"[INFO|training_args.py:1327] 2023-09-02 18:37:47,712 >> Found safetensors installation, but --save_safetensors=False. Safetensors should be a preferred weights saving format due to security and performance reasons. If your model cannot be saved by safetensors please feel free to open an issue at https://github.com/huggingface/safetensors!\n[INFO|training_args.py:1769] 2023-09-02 18:37:47,715 >> PyTorch: setting up devices\n[INFO|training_args.py:1480] 2023-09-02 18:37:47,719 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","output_type":"stream"}]},{"cell_type":"code","source":"transformers.utils.logging.set_verbosity_info()\n\nlog_level = training_args.get_process_log_level()\nlogger.setLevel(log_level)\ndatasets.utils.logging.set_verbosity(log_level)\ntransformers.utils.logging.set_verbosity(log_level)\ntransformers.utils.logging.enable_default_handler()\ntransformers.utils.logging.enable_explicit_format()\nlogger.warning(\n    f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n    + f\" distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n)\nlogger.info(f\"Training/evaluation parameters {training_args}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:47.731484Z","iopub.execute_input":"2023-09-02T18:37:47.731843Z","iopub.status.idle":"2023-09-02T18:37:47.751966Z","shell.execute_reply.started":"2023-09-02T18:37:47.731799Z","shell.execute_reply":"2023-09-02T18:37:47.750857Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"model_name = 'xlm-roberta-base'","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:47.756960Z","iopub.execute_input":"2023-09-02T18:37:47.759571Z","iopub.status.idle":"2023-09-02T18:37:47.768909Z","shell.execute_reply.started":"2023-09-02T18:37:47.759533Z","shell.execute_reply":"2023-09-02T18:37:47.767609Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"set_seed(training_args.seed)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:47.774678Z","iopub.execute_input":"2023-09-02T18:37:47.775375Z","iopub.status.idle":"2023-09-02T18:37:47.790183Z","shell.execute_reply.started":"2023-09-02T18:37:47.775349Z","shell.execute_reply":"2023-09-02T18:37:47.789140Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"punctuations = [\"|\",\"‘\",\">\",\"<\",\"*\",   \"।\", \",\", \";\", \":\", \"?\", \"!\", \"'\", \".\", \"\\\"\", \"-\",\n                \"[\", \"]\", \"{\", \"}\", \"(\", \")\", '–', \"—\", \"―\", \"~\"]\n\ndef remove_url(word):\n    return word.split(\"http\")[0].strip()\n\ndef extreme_process(word):\n    word_list = [word]\n    splitter_list = [\"**\",\"*\", \"…\", \"-\"]\n\n    for i in splitter_list:\n        if i in word:\n            temp_list = word.split(i)\n            word_list = list(filter(lambda x:x.strip() != \"\", temp_list))\n            return word_list\n    return word_list\n\n\ndef process_word(word):\n    word = word.strip()\n    if len(word) == 0:\n        return []\n    elif len(word) == 1:\n        if word not in punctuations:\n            return [word]\n        else:\n            return []\n    else:\n        word = remove_url(word)\n\n        if len(word) == 0:\n            return []\n        elif len(word) == 1:\n            if word in punctuations:\n                return []\n            else:\n                return [word]\n        else:\n            if word[0] in punctuations:\n                word = word[1:]\n            if word[-1] in punctuations:\n                word = word[:-1]\n\n            word = extreme_process(word)\n\n            return word\n","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:47.791249Z","iopub.execute_input":"2023-09-02T18:37:47.791577Z","iopub.status.idle":"2023-09-02T18:37:47.813114Z","shell.execute_reply.started":"2023-09-02T18:37:47.791545Z","shell.execute_reply":"2023-09-02T18:37:47.811885Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"l2id = {'Positive': 2, 'Neutral': 1, 'Negative': 0}\ntrain_df = pd.read_csv(train_file, sep='\\t')\nprint(train_df.head())","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:47.814949Z","iopub.execute_input":"2023-09-02T18:37:47.815691Z","iopub.status.idle":"2023-09-02T18:37:48.030180Z","shell.execute_reply.started":"2023-09-02T18:37:47.815653Z","shell.execute_reply":"2023-09-02T18:37:48.026686Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"               id                                               text     label\n0           10856  এখানে আরো ভালো ভাবে দলীয় ও র এর অবস্থান পাকা হ...   Neutral\n1   sentinob_1072                   চুয়াডাঙ্গা বাড়ি কে বলেছে আপনার   Neutral\n2  sentinob_10530      ভাই সোনাই ঘোষ এর দই খেয়ে যাইতেন , খুব ই মজার   Positive\n3            8001  সমার তালুকদার আপনার ছবিতে ফেসটা কেন জানি বন্য ...  Negative\n4  sentinob_10144  ভাইয়া এই নুডলস টা কোথায় কিনতে পাওয়া যাবে প্লিজ...  Positive\n","output_type":"stream"}]},{"cell_type":"code","source":"for index, row in train_df.iterrows():\n    unprocessed_spliited_word = row[\"text\"].split(\" \")\n    processed_word_list = []\n    for i in unprocessed_spliited_word:\n        processed_word_list += process_word(i)\n    train_df.at[index, \"text\"] = \" \".join(processed_word_list)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:48.031733Z","iopub.execute_input":"2023-09-02T18:37:48.034583Z","iopub.status.idle":"2023-09-02T18:37:53.128178Z","shell.execute_reply.started":"2023-09-02T18:37:48.034536Z","shell.execute_reply":"2023-09-02T18:37:53.127060Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"train_df['label'] = train_df['label'].map(l2id)\nprint(train_df.head())","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:53.129603Z","iopub.execute_input":"2023-09-02T18:37:53.130297Z","iopub.status.idle":"2023-09-02T18:37:53.149079Z","shell.execute_reply.started":"2023-09-02T18:37:53.130255Z","shell.execute_reply":"2023-09-02T18:37:53.147535Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"               id                                               text  label\n0           10856  এখানে আরো ভালো ভাবে দলীয় ও র এর অবস্থান পাকা হ...      1\n1   sentinob_1072                   চুয়াডাঙ্গা বাড়ি কে বলেছে আপনার      1\n2  sentinob_10530         ভাই সোনাই ঘোষ এর দই খেয়ে যাইতেন খুব ই মজার      2\n3            8001  সমার তালুকদার আপনার ছবিতে ফেসটা কেন জানি বন্য ...      0\n4  sentinob_10144  ভাইয়া এই নুডলস টা কোথায় কিনতে পাওয়া যাবে প্লিজ...      2\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df = Dataset.from_pandas(train_df)\nprint(train_df)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:53.152889Z","iopub.execute_input":"2023-09-02T18:37:53.158492Z","iopub.status.idle":"2023-09-02T18:37:53.230798Z","shell.execute_reply.started":"2023-09-02T18:37:53.158456Z","shell.execute_reply":"2023-09-02T18:37:53.223936Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['id', 'text', 'label'],\n    num_rows: 35266\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"validation_df = pd.read_csv(validation_file, sep='\\t')\nfor index, row in validation_df.iterrows():\n    unprocessed_spliited_word = row[\"text\"].split(\" \")\n    processed_word_list = []\n    for i in unprocessed_spliited_word:\n        processed_word_list += process_word(i)\n    validation_df.at[index, \"text\"] = \" \".join(processed_word_list)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:53.235849Z","iopub.execute_input":"2023-09-02T18:37:53.238943Z","iopub.status.idle":"2023-09-02T18:37:53.835644Z","shell.execute_reply.started":"2023-09-02T18:37:53.238888Z","shell.execute_reply":"2023-09-02T18:37:53.834421Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"validation_df['label'] = validation_df['label'].map(l2id)\nvalidation_df = Dataset.from_pandas(validation_df)\nprint(validation_df)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:53.840814Z","iopub.execute_input":"2023-09-02T18:37:53.841702Z","iopub.status.idle":"2023-09-02T18:37:53.867942Z","shell.execute_reply.started":"2023-09-02T18:37:53.841663Z","shell.execute_reply":"2023-09-02T18:37:53.866881Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['id', 'text', 'label'],\n    num_rows: 3934\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"old_test_df = pd.read_csv(test_file, sep='\\t')\nprint(old_test_df.head())\nprint(len(old_test_df))","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:53.869586Z","iopub.execute_input":"2023-09-02T18:37:53.870008Z","iopub.status.idle":"2023-09-02T18:37:53.910212Z","shell.execute_reply.started":"2023-09-02T18:37:53.869970Z","shell.execute_reply":"2023-09-02T18:37:53.908755Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"      id                                               text\n0  30670   * করোনায় আরো ১৮৭ জনের মৃত্যু; মোট প্রাণহানি ...\n1   4125          চাপাবাজীর চাপে এবার ধামাচাপা পড়বে আসল ইসু\n2  27077   কুয়েতে বাংলাদেশী ফল খেতে হামলে পড়ছেন প্রবাসীরা\n3  17552  তিনি ছিলেন টেস্ট খেলা সবচেয়ে বেশি বয়সী জীবিত...\n4   4137  চাল আর পাট গুলো উৎপাদন করতে যে কৃষকের বাঁশ ঢুক...\n3426\n","output_type":"stream"}]},{"cell_type":"code","source":"test_df = pd.read_csv(\"/kaggle/working/blp23_sentiment_test_with_label.tsv\", sep=\"\\t\")\nprint(test_df.head())\nprint(len(test_df))","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:53.911613Z","iopub.execute_input":"2023-09-02T18:37:53.912046Z","iopub.status.idle":"2023-09-02T18:37:53.984970Z","shell.execute_reply.started":"2023-09-02T18:37:53.912005Z","shell.execute_reply":"2023-09-02T18:37:53.983736Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"      id                                               text     label\n0   7135  মুখস্ত শিক্ষা দিয়ে কি করবে এই জাতি ? বাংলাদেশ...  Negative\n1  28949  জর্ডানের সাবেক যুবরাজ প্রিন্স হামজার ভিডিও বার...  Negative\n2  10210  আমার ছেলের দুর্ভাগ্য না সৌভাগ্য জানিনা জ্বর এর...   Neutral\n3   9526  Pranoy Sen তখন পাকিস্তান ও আফগানিস্তান ভারতের ...   Neutral\n4   2142                              আরো কত মিথ্যাচার করবে  Negative\n6707\n","output_type":"stream"}]},{"cell_type":"code","source":"test_df['label'] = test_df['label'].map(l2id)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:53.989835Z","iopub.execute_input":"2023-09-02T18:37:53.993174Z","iopub.status.idle":"2023-09-02T18:37:54.004696Z","shell.execute_reply.started":"2023-09-02T18:37:53.993130Z","shell.execute_reply":"2023-09-02T18:37:54.003275Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"for index, row in test_df.iterrows():\n    unprocessed_spliited_word = row[\"text\"].split(\" \")\n    processed_word_list = []\n    for i in unprocessed_spliited_word:\n        processed_word_list += process_word(i)\n    test_df.at[index, \"text\"] = \" \".join(processed_word_list)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:54.006476Z","iopub.execute_input":"2023-09-02T18:37:54.007356Z","iopub.status.idle":"2023-09-02T18:37:54.948530Z","shell.execute_reply.started":"2023-09-02T18:37:54.007239Z","shell.execute_reply":"2023-09-02T18:37:54.944013Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"test_df = Dataset.from_pandas(test_df)\nprint(test_df)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:54.950275Z","iopub.execute_input":"2023-09-02T18:37:54.950950Z","iopub.status.idle":"2023-09-02T18:37:54.972522Z","shell.execute_reply.started":"2023-09-02T18:37:54.950898Z","shell.execute_reply":"2023-09-02T18:37:54.971437Z"},"trusted":true},"execution_count":85,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['id', 'text', 'label'],\n    num_rows: 6707\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"data_files = {\"train\": train_df, \"validation\": validation_df, \"test\": test_df}\nfor key in data_files.keys():\n    logger.info(f\"loading a local file for {key}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:54.973978Z","iopub.execute_input":"2023-09-02T18:37:54.974547Z","iopub.status.idle":"2023-09-02T18:37:54.982872Z","shell.execute_reply.started":"2023-09-02T18:37:54.974513Z","shell.execute_reply":"2023-09-02T18:37:54.981872Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"raw_datasets = DatasetDict(\n    {\"train\": train_df, \"validation\": validation_df, \"test\": test_df}\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:54.984404Z","iopub.execute_input":"2023-09-02T18:37:54.985110Z","iopub.status.idle":"2023-09-02T18:37:54.994296Z","shell.execute_reply.started":"2023-09-02T18:37:54.985048Z","shell.execute_reply":"2023-09-02T18:37:54.993646Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"print(raw_datasets)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:54.995521Z","iopub.execute_input":"2023-09-02T18:37:54.996072Z","iopub.status.idle":"2023-09-02T18:37:55.010509Z","shell.execute_reply.started":"2023-09-02T18:37:54.996038Z","shell.execute_reply":"2023-09-02T18:37:55.009493Z"},"trusted":true},"execution_count":88,"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'text', 'label'],\n        num_rows: 35266\n    })\n    validation: Dataset({\n        features: ['id', 'text', 'label'],\n        num_rows: 3934\n    })\n    test: Dataset({\n        features: ['id', 'text', 'label'],\n        num_rows: 6707\n    })\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"label_list = raw_datasets[\"train\"].unique(\"label\")\nprint(label_list)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:55.011733Z","iopub.execute_input":"2023-09-02T18:37:55.012090Z","iopub.status.idle":"2023-09-02T18:37:55.032499Z","shell.execute_reply.started":"2023-09-02T18:37:55.012058Z","shell.execute_reply":"2023-09-02T18:37:55.031545Z"},"trusted":true},"execution_count":89,"outputs":[{"name":"stdout","text":"[1, 2, 0]\n","output_type":"stream"}]},{"cell_type":"code","source":"label_list.sort()  # sort the labels for determine\nprint(label_list)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:55.033892Z","iopub.execute_input":"2023-09-02T18:37:55.034304Z","iopub.status.idle":"2023-09-02T18:37:55.046729Z","shell.execute_reply.started":"2023-09-02T18:37:55.034258Z","shell.execute_reply":"2023-09-02T18:37:55.045773Z"},"trusted":true},"execution_count":90,"outputs":[{"name":"stdout","text":"[0, 1, 2]\n","output_type":"stream"}]},{"cell_type":"code","source":"num_labels = len(label_list)\nprint(num_labels)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:55.060325Z","iopub.execute_input":"2023-09-02T18:37:55.060739Z","iopub.status.idle":"2023-09-02T18:37:55.068235Z","shell.execute_reply.started":"2023-09-02T18:37:55.060705Z","shell.execute_reply":"2023-09-02T18:37:55.066978Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stdout","text":"3\n","output_type":"stream"}]},{"cell_type":"code","source":"config = AutoConfig.from_pretrained(\n    model_name,\n    num_labels=num_labels,\n    finetuning_task=None,\n    cache_dir=None,\n    revision=\"main\",\n    use_auth_token=None,\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:55.069544Z","iopub.execute_input":"2023-09-02T18:37:55.070040Z","iopub.status.idle":"2023-09-02T18:37:55.220251Z","shell.execute_reply.started":"2023-09-02T18:37:55.069998Z","shell.execute_reply":"2023-09-02T18:37:55.219160Z"},"trusted":true},"execution_count":92,"outputs":[{"name":"stderr","text":"[INFO|configuration_utils.py:715] 2023-09-02 18:37:55,209 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n[INFO|configuration_utils.py:775] 2023-09-02 18:37:55,215 >> Model config XLMRobertaConfig {\n  \"_name_or_path\": \"xlm-roberta-base\",\n  \"architectures\": [\n    \"XLMRobertaForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"xlm-roberta\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"output_past\": true,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.32.1\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 250002\n}\n\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\n    model_name,\n    cache_dir=None,\n    use_fast=True,\n    revision=\"main\",\n    use_auth_token=None,\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:55.221784Z","iopub.execute_input":"2023-09-02T18:37:55.222392Z","iopub.status.idle":"2023-09-02T18:37:56.291571Z","shell.execute_reply.started":"2023-09-02T18:37:55.222353Z","shell.execute_reply":"2023-09-02T18:37:56.287323Z"},"trusted":true},"execution_count":93,"outputs":[{"name":"stderr","text":"[INFO|tokenization_auto.py:526] 2023-09-02 18:37:55,284 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n[INFO|configuration_utils.py:715] 2023-09-02 18:37:55,332 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n[INFO|configuration_utils.py:775] 2023-09-02 18:37:55,335 >> Model config XLMRobertaConfig {\n  \"_name_or_path\": \"xlm-roberta-base\",\n  \"architectures\": [\n    \"XLMRobertaForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"xlm-roberta\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"output_past\": true,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.32.1\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 250002\n}\n\n[INFO|tokenization_utils_base.py:1852] 2023-09-02 18:37:55,461 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/sentencepiece.bpe.model\n[INFO|tokenization_utils_base.py:1852] 2023-09-02 18:37:55,462 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/tokenizer.json\n[INFO|tokenization_utils_base.py:1852] 2023-09-02 18:37:55,463 >> loading file added_tokens.json from cache at None\n[INFO|tokenization_utils_base.py:1852] 2023-09-02 18:37:55,465 >> loading file special_tokens_map.json from cache at None\n[INFO|tokenization_utils_base.py:1852] 2023-09-02 18:37:55,467 >> loading file tokenizer_config.json from cache at None\n[INFO|configuration_utils.py:715] 2023-09-02 18:37:55,469 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\n[INFO|configuration_utils.py:775] 2023-09-02 18:37:55,472 >> Model config XLMRobertaConfig {\n  \"_name_or_path\": \"xlm-roberta-base\",\n  \"architectures\": [\n    \"XLMRobertaForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"xlm-roberta\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"output_past\": true,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.32.1\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 250002\n}\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    from_tf=bool(\".ckpt\" in model_name),\n    config=config,\n    cache_dir=None,\n    revision=\"main\",\n    use_auth_token=None,\n    ignore_mismatched_sizes=False,\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:37:56.292994Z","iopub.execute_input":"2023-09-02T18:37:56.295994Z","iopub.status.idle":"2023-09-02T18:38:05.885640Z","shell.execute_reply.started":"2023-09-02T18:37:56.295954Z","shell.execute_reply":"2023-09-02T18:38:05.884538Z"},"trusted":true},"execution_count":94,"outputs":[{"name":"stderr","text":"[INFO|modeling_utils.py:2779] 2023-09-02 18:37:56,302 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/model.safetensors\n[INFO|modeling_utils.py:3541] 2023-09-02 18:38:05,840 >> Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n[WARNING|modeling_utils.py:3553] 2023-09-02 18:38:05,842 >> Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"Model Name: {model_name}\")\nprint(f\"Number of Layers: {config.num_hidden_layers}\")\nprint(f\"Hidden Dimension: {config.hidden_size}\")\nprint(f\"Number of Attention Heads: {config.num_attention_heads}\")\nprint(f\"Intermediate Dimension: {config.intermediate_size}\")\nprint(f\"Total Parameters: {model.num_parameters()}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:38:05.887266Z","iopub.execute_input":"2023-09-02T18:38:05.887868Z","iopub.status.idle":"2023-09-02T18:38:05.903661Z","shell.execute_reply.started":"2023-09-02T18:38:05.887830Z","shell.execute_reply":"2023-09-02T18:38:05.902622Z"},"trusted":true},"execution_count":95,"outputs":[{"name":"stdout","text":"Model Name: xlm-roberta-base\nNumber of Layers: 12\nHidden Dimension: 768\nNumber of Attention Heads: 12\nIntermediate Dimension: 3072\nTotal Parameters: 278045955\n","output_type":"stream"}]},{"cell_type":"code","source":"non_label_column_names = [name for name in raw_datasets[\"train\"].column_names if name != \"label\"]\nprint(non_label_column_names)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:38:05.905279Z","iopub.execute_input":"2023-09-02T18:38:05.905940Z","iopub.status.idle":"2023-09-02T18:38:05.917101Z","shell.execute_reply.started":"2023-09-02T18:38:05.905905Z","shell.execute_reply":"2023-09-02T18:38:05.916054Z"},"trusted":true},"execution_count":96,"outputs":[{"name":"stdout","text":"['id', 'text']\n","output_type":"stream"}]},{"cell_type":"code","source":"sentence_key= non_label_column_names[1]\nprint(sentence_key)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:38:05.918758Z","iopub.execute_input":"2023-09-02T18:38:05.919463Z","iopub.status.idle":"2023-09-02T18:38:05.930936Z","shell.execute_reply.started":"2023-09-02T18:38:05.919428Z","shell.execute_reply":"2023-09-02T18:38:05.929934Z"},"trusted":true},"execution_count":97,"outputs":[{"name":"stdout","text":"text\n","output_type":"stream"}]},{"cell_type":"code","source":"padding = \"max_length\"\nlabel_to_id = None\n\nif (model.config.label2id != PretrainedConfig(num_labels=num_labels).label2id):\n    # Some have all caps in their config, some don't.\n    label_name_to_id = {k.lower(): v for k, v in model.config.label2id.items()}\n    if sorted(label_name_to_id.keys()) == sorted(label_list):\n        label_to_id = {i: int(label_name_to_id[label_list[i]]) for i in range(num_labels)}\n    else:\n        logger.warning(\n            \"Your model seems to have been trained with labels, but they don't match the dataset: \",\n            f\"model labels: {sorted(label_name_to_id.keys())}, dataset labels: {sorted(label_list)}.\"\n            \"\\nIgnoring the model labels as a result.\",)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:38:05.932694Z","iopub.execute_input":"2023-09-02T18:38:05.933344Z","iopub.status.idle":"2023-09-02T18:38:05.945601Z","shell.execute_reply.started":"2023-09-02T18:38:05.933308Z","shell.execute_reply":"2023-09-02T18:38:05.944577Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"if label_to_id is not None:\n    model.config.label2id = label_to_id\n    model.config.id2label = {id: label for label, id in config.label2id.items()}","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:38:05.947235Z","iopub.execute_input":"2023-09-02T18:38:05.947850Z","iopub.status.idle":"2023-09-02T18:38:05.961528Z","shell.execute_reply.started":"2023-09-02T18:38:05.947804Z","shell.execute_reply":"2023-09-02T18:38:05.960310Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"if 128 > tokenizer.model_max_length:\n    logger.warning(\n        f\"The max_seq_length passed ({128}) is larger than the maximum length for the\"\n        f\"model ({tokenizer.model_max_length}). Using max_seq_length={tokenizer.model_max_length}.\")","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:38:05.963328Z","iopub.execute_input":"2023-09-02T18:38:05.964040Z","iopub.status.idle":"2023-09-02T18:38:05.977370Z","shell.execute_reply.started":"2023-09-02T18:38:05.964005Z","shell.execute_reply":"2023-09-02T18:38:05.976404Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"max_seq_length = min(128, tokenizer.model_max_length)\nprint(max_seq_length)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:38:05.978756Z","iopub.execute_input":"2023-09-02T18:38:05.979455Z","iopub.status.idle":"2023-09-02T18:38:05.990051Z","shell.execute_reply.started":"2023-09-02T18:38:05.979421Z","shell.execute_reply":"2023-09-02T18:38:05.988903Z"},"trusted":true},"execution_count":101,"outputs":[{"name":"stdout","text":"128\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    # Tokenize the texts\n    args = (\n        (examples[sentence_key],))\n    result = tokenizer(*args, padding=padding, max_length=max_seq_length, truncation=True)\n\n    # Map labels to IDs (not necessary for GLUE tasks)\n    if label_to_id is not None and \"label\" in examples:\n        result[\"label\"] = [(label_to_id[l] if l != -1 else -1) for l in examples[\"label\"]]\n    return result","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:38:05.991489Z","iopub.execute_input":"2023-09-02T18:38:05.992579Z","iopub.status.idle":"2023-09-02T18:38:06.005936Z","shell.execute_reply.started":"2023-09-02T18:38:05.992544Z","shell.execute_reply":"2023-09-02T18:38:06.004888Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"raw_datasets = raw_datasets.map(\n    preprocess_function,\n    batched=True,\n    load_from_cache_file=True,\n    desc=\"Running tokenizer on dataset\",\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:38:06.007327Z","iopub.execute_input":"2023-09-02T18:38:06.007770Z","iopub.status.idle":"2023-09-02T18:38:13.837950Z","shell.execute_reply.started":"2023-09-02T18:38:06.007731Z","shell.execute_reply":"2023-09-02T18:38:13.836829Z"},"trusted":true},"execution_count":103,"outputs":[{"output_type":"display_data","data":{"text/plain":"Running tokenizer on dataset:   0%|          | 0/36 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73677168c54b44428cb8b749294de1b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on dataset:   0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f6421e2f9284371ac2a6e7462842c88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on dataset:   0%|          | 0/7 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5439950d82c45d6ab0ba0dc703067eb"}},"metadata":{}}]},{"cell_type":"code","source":"if \"train\" not in raw_datasets:\n    raise ValueError(\"requires a train dataset\")","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:38:13.839600Z","iopub.execute_input":"2023-09-02T18:38:13.840688Z","iopub.status.idle":"2023-09-02T18:38:13.846968Z","shell.execute_reply.started":"2023-09-02T18:38:13.840650Z","shell.execute_reply":"2023-09-02T18:38:13.845513Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"train_dataset = raw_datasets[\"train\"]\nprint(train_dataset) ","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:38:13.848631Z","iopub.execute_input":"2023-09-02T18:38:13.849844Z","iopub.status.idle":"2023-09-02T18:38:13.861515Z","shell.execute_reply.started":"2023-09-02T18:38:13.849788Z","shell.execute_reply":"2023-09-02T18:38:13.860533Z"},"trusted":true},"execution_count":105,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['id', 'text', 'label', 'input_ids', 'attention_mask'],\n    num_rows: 35266\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"if \"validation\" not in raw_datasets:\n    raise ValueError(\"requires a validation dataset\")","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:38:13.863137Z","iopub.execute_input":"2023-09-02T18:38:13.863807Z","iopub.status.idle":"2023-09-02T18:38:13.873293Z","shell.execute_reply.started":"2023-09-02T18:38:13.863766Z","shell.execute_reply":"2023-09-02T18:38:13.871908Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"eval_dataset = raw_datasets[\"validation\"]\nprint(eval_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:38:13.875934Z","iopub.execute_input":"2023-09-02T18:38:13.876442Z","iopub.status.idle":"2023-09-02T18:38:13.885032Z","shell.execute_reply.started":"2023-09-02T18:38:13.876406Z","shell.execute_reply":"2023-09-02T18:38:13.882863Z"},"trusted":true},"execution_count":107,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['id', 'text', 'label', 'input_ids', 'attention_mask'],\n    num_rows: 3934\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"print(max_eval_samples)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:38:13.886643Z","iopub.execute_input":"2023-09-02T18:38:13.887058Z","iopub.status.idle":"2023-09-02T18:38:13.898445Z","shell.execute_reply.started":"2023-09-02T18:38:13.887023Z","shell.execute_reply":"2023-09-02T18:38:13.896188Z"},"trusted":true},"execution_count":108,"outputs":[{"name":"stdout","text":"None\n","output_type":"stream"}]},{"cell_type":"code","source":"if max_eval_samples is not None:\n    max_eval_samples_n = min(len(eval_dataset), max_eval_samples)\n    eval_dataset = eval_dataset.select(range(max_eval_samples_n))","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:38:13.899516Z","iopub.execute_input":"2023-09-02T18:38:13.900012Z","iopub.status.idle":"2023-09-02T18:38:13.911430Z","shell.execute_reply.started":"2023-09-02T18:38:13.899978Z","shell.execute_reply":"2023-09-02T18:38:13.910277Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"if \"test\" not in raw_datasets and \"test_matched\" not in raw_datasets:\n    raise ValueError(\"requires a test dataset\")","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:38:13.912468Z","iopub.execute_input":"2023-09-02T18:38:13.912785Z","iopub.status.idle":"2023-09-02T18:38:13.933225Z","shell.execute_reply.started":"2023-09-02T18:38:13.912753Z","shell.execute_reply":"2023-09-02T18:38:13.931887Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"predict_dataset = raw_datasets[\"test\"]\nprint(predict_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:38:13.934556Z","iopub.execute_input":"2023-09-02T18:38:13.935032Z","iopub.status.idle":"2023-09-02T18:38:13.946020Z","shell.execute_reply.started":"2023-09-02T18:38:13.934994Z","shell.execute_reply":"2023-09-02T18:38:13.944858Z"},"trusted":true},"execution_count":111,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['id', 'text', 'label', 'input_ids', 'attention_mask'],\n    num_rows: 6707\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"print(max_predict_samples)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:38:13.948006Z","iopub.execute_input":"2023-09-02T18:38:13.948452Z","iopub.status.idle":"2023-09-02T18:38:13.960525Z","shell.execute_reply.started":"2023-09-02T18:38:13.948416Z","shell.execute_reply":"2023-09-02T18:38:13.959394Z"},"trusted":true},"execution_count":112,"outputs":[{"name":"stdout","text":"None\n","output_type":"stream"}]},{"cell_type":"code","source":"if max_predict_samples is not None:\n    max_predict_samples_n = min(len(predict_dataset), max_predict_samples)\n    predict_dataset = predict_dataset.select(range(max_predict_samples_n))","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:38:13.961578Z","iopub.execute_input":"2023-09-02T18:38:13.961969Z","iopub.status.idle":"2023-09-02T18:38:13.973699Z","shell.execute_reply.started":"2023-09-02T18:38:13.961931Z","shell.execute_reply":"2023-09-02T18:38:13.972503Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"for index in random.sample(range(len(train_dataset)), 3):\n    logger.info(f\"Sample {index} of the training set: {train_dataset[index]}.\")","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:38:13.975321Z","iopub.execute_input":"2023-09-02T18:38:13.975723Z","iopub.status.idle":"2023-09-02T18:38:13.987381Z","shell.execute_reply.started":"2023-09-02T18:38:13.975682Z","shell.execute_reply":"2023-09-02T18:38:13.986458Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"metric = evaluate.load(\"accuracy\")","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:38:13.988570Z","iopub.execute_input":"2023-09-02T18:38:13.989150Z","iopub.status.idle":"2023-09-02T18:38:14.378049Z","shell.execute_reply.started":"2023-09-02T18:38:13.989114Z","shell.execute_reply":"2023-09-02T18:38:14.376957Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"def calculate_micro_f1_score(true_positives, false_positives, false_negatives):\n    total_tp = sum(true_positives)\n    total_fp = sum(false_positives)\n    total_fn = sum(false_negatives)\n\n    micro_precision = total_tp / (total_tp + total_fp + 1e-9)\n    micro_recall = total_tp / (total_tp + total_fn + 1e-9)\n\n    micro_f1 = 2 * (micro_precision * micro_recall) / (micro_precision + micro_recall + 1e-9)\n\n    return micro_f1","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:38:14.379571Z","iopub.execute_input":"2023-09-02T18:38:14.380216Z","iopub.status.idle":"2023-09-02T18:38:14.389485Z","shell.execute_reply.started":"2023-09-02T18:38:14.380178Z","shell.execute_reply":"2023-09-02T18:38:14.388019Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(p: EvalPrediction):\n    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n    preds = np.argmax(preds, axis=1)\n\n    labels = p.label_ids\n    # Initialize dictionaries to store TP, FP, and FN for each class\n    true_positives = {label: 0 for label in range(num_labels)}\n    false_positives = {label: 0 for label in range(num_labels)}\n    false_negatives = {label: 0 for label in range(num_labels)}\n\n    for label, pred in zip(labels, preds):\n        for class_id in range(num_labels):\n            if class_id == label and class_id == pred:\n                true_positives[class_id] += 1\n            elif class_id != label and class_id == pred:\n                false_positives[class_id] += 1\n            elif class_id == label and class_id != pred:\n                false_negatives[class_id] += 1\n\n    return {\n        \"micro_f1_score\": calculate_micro_f1_score(\n            list(true_positives.values()), list(false_positives.values()), list(false_negatives.values())\n        ),\n        \"accuracy\": (preds == p.label_ids).astype(np.float32).mean().item()\n    }\n","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:38:14.391129Z","iopub.execute_input":"2023-09-02T18:38:14.391928Z","iopub.status.idle":"2023-09-02T18:38:14.404275Z","shell.execute_reply.started":"2023-09-02T18:38:14.391885Z","shell.execute_reply":"2023-09-02T18:38:14.403181Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"data_collator = default_data_collator","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:38:14.405747Z","iopub.execute_input":"2023-09-02T18:38:14.406409Z","iopub.status.idle":"2023-09-02T18:38:14.418831Z","shell.execute_reply.started":"2023-09-02T18:38:14.406375Z","shell.execute_reply":"2023-09-02T18:38:14.417196Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:38:14.419797Z","iopub.execute_input":"2023-09-02T18:38:14.420303Z","iopub.status.idle":"2023-09-02T18:38:14.430666Z","shell.execute_reply.started":"2023-09-02T18:38:14.420262Z","shell.execute_reply":"2023-09-02T18:38:14.429181Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\ntraining_args = TrainingArguments(\n    output_dir=\"./output\",\n    evaluation_strategy=\"steps\",  # Changed to \"steps\"\n    logging_dir=\"./logs\",\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    learning_rate=2e-5,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    save_total_limit=3,  # Limit the number of saved checkpoints\n    load_best_model_at_end=True,\n)\n\n# Initialize the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    compute_metrics=compute_metrics,\n    tokenizer=tokenizer,\n)\n\n# Perform cross-validation\nresults = trainer.evaluate()\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:38:14.431639Z","iopub.execute_input":"2023-09-02T18:38:14.432074Z","iopub.status.idle":"2023-09-02T18:38:55.570240Z","shell.execute_reply.started":"2023-09-02T18:38:14.432041Z","shell.execute_reply":"2023-09-02T18:38:55.569169Z"},"trusted":true},"execution_count":120,"outputs":[{"name":"stderr","text":"[INFO|training_args.py:1271] 2023-09-02 18:38:14,442 >> using `logging_steps` to initialize `eval_steps` to 500\n[INFO|training_args.py:1327] 2023-09-02 18:38:14,444 >> Found safetensors installation, but --save_safetensors=False. Safetensors should be a preferred weights saving format due to security and performance reasons. If your model cannot be saved by safetensors please feel free to open an issue at https://github.com/huggingface/safetensors!\n[INFO|training_args.py:1769] 2023-09-02 18:38:14,445 >> PyTorch: setting up devices\n[INFO|training_args.py:1480] 2023-09-02 18:38:14,448 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n[WARNING|integrations.py:81] 2023-09-02 18:38:14,457 >> Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n[INFO|trainer.py:750] 2023-09-02 18:38:14,778 >> The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: id, text. If id, text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n[INFO|trainer.py:3119] 2023-09-02 18:38:14,784 >> ***** Running Evaluation *****\n[INFO|trainer.py:3121] 2023-09-02 18:38:14,785 >>   Num examples = 3934\n[INFO|trainer.py:3124] 2023-09-02 18:38:14,787 >>   Batch size = 16\n[WARNING|logging.py:290] 2023-09-02 18:38:14,795 >> You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='492' max='246' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [246/246 05:45]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 1.128901481628418, 'eval_micro_f1_score': 0.20157600356705604, 'eval_accuracy': 0.20157600939273834, 'eval_runtime': 40.7588, 'eval_samples_per_second': 96.519, 'eval_steps_per_second': 6.036}\n","output_type":"stream"}]},{"cell_type":"code","source":"train_result = trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-09-02T18:38:55.574944Z","iopub.execute_input":"2023-09-02T18:38:55.577868Z","iopub.status.idle":"2023-09-02T19:48:40.514931Z","shell.execute_reply.started":"2023-09-02T18:38:55.577824Z","shell.execute_reply":"2023-09-02T19:48:40.513964Z"},"trusted":true},"execution_count":121,"outputs":[{"name":"stderr","text":"[INFO|trainer.py:750] 2023-09-02 18:38:56,026 >> The following columns in the training set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: id, text. If id, text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n[INFO|trainer.py:1714] 2023-09-02 18:38:56,036 >> ***** Running training *****\n[INFO|trainer.py:1715] 2023-09-02 18:38:56,038 >>   Num examples = 35,266\n[INFO|trainer.py:1716] 2023-09-02 18:38:56,040 >>   Num Epochs = 3\n[INFO|trainer.py:1717] 2023-09-02 18:38:56,041 >>   Instantaneous batch size per device = 8\n[INFO|trainer.py:1719] 2023-09-02 18:38:56,043 >>   Training with DataParallel so batch size has been adjusted to: 16\n[INFO|trainer.py:1720] 2023-09-02 18:38:56,044 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n[INFO|trainer.py:1721] 2023-09-02 18:38:56,045 >>   Gradient Accumulation steps = 1\n[INFO|trainer.py:1722] 2023-09-02 18:38:56,046 >>   Total optimization steps = 6,615\n[INFO|trainer.py:1723] 2023-09-02 18:38:56,049 >>   Number of trainable parameters = 278,045,955\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6615' max='6615' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6615/6615 1:09:43, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Micro F1 Score</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>1.058900</td>\n      <td>1.052202</td>\n      <td>0.444840</td>\n      <td>0.444840</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>1.039800</td>\n      <td>1.001858</td>\n      <td>0.527707</td>\n      <td>0.527707</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.985400</td>\n      <td>0.923109</td>\n      <td>0.579054</td>\n      <td>0.579054</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.922200</td>\n      <td>0.958219</td>\n      <td>0.565074</td>\n      <td>0.565074</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.895200</td>\n      <td>0.891963</td>\n      <td>0.607778</td>\n      <td>0.607778</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.838800</td>\n      <td>0.878296</td>\n      <td>0.628622</td>\n      <td>0.628622</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.840000</td>\n      <td>0.845451</td>\n      <td>0.633452</td>\n      <td>0.633452</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.829800</td>\n      <td>0.810183</td>\n      <td>0.646924</td>\n      <td>0.646924</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.785100</td>\n      <td>0.847109</td>\n      <td>0.657855</td>\n      <td>0.657855</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.757600</td>\n      <td>0.819014</td>\n      <td>0.652262</td>\n      <td>0.652262</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.755200</td>\n      <td>0.811590</td>\n      <td>0.655567</td>\n      <td>0.655567</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.754400</td>\n      <td>0.803179</td>\n      <td>0.657855</td>\n      <td>0.657855</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>0.750400</td>\n      <td>0.806826</td>\n      <td>0.660397</td>\n      <td>0.660397</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"[INFO|trainer.py:750] 2023-09-02 18:43:20,320 >> The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: id, text. If id, text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n[INFO|trainer.py:3119] 2023-09-02 18:43:20,324 >> ***** Running Evaluation *****\n[INFO|trainer.py:3121] 2023-09-02 18:43:20,325 >>   Num examples = 3934\n[INFO|trainer.py:3124] 2023-09-02 18:43:20,327 >>   Batch size = 16\n[INFO|trainer.py:2845] 2023-09-02 18:44:00,775 >> Saving model checkpoint to ./output/checkpoint-500\n[INFO|configuration_utils.py:460] 2023-09-02 18:44:00,779 >> Configuration saved in ./output/checkpoint-500/config.json\n[INFO|modeling_utils.py:1953] 2023-09-02 18:44:03,109 >> Model weights saved in ./output/checkpoint-500/pytorch_model.bin\n[INFO|tokenization_utils_base.py:2235] 2023-09-02 18:44:03,115 >> tokenizer config file saved in ./output/checkpoint-500/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2242] 2023-09-02 18:44:03,121 >> Special tokens file saved in ./output/checkpoint-500/special_tokens_map.json\n[INFO|trainer.py:2932] 2023-09-02 18:44:11,141 >> Deleting older checkpoint [output/checkpoint-4000] due to args.save_total_limit\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n[INFO|trainer.py:750] 2023-09-02 18:48:35,977 >> The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: id, text. If id, text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n[INFO|trainer.py:3119] 2023-09-02 18:48:35,982 >> ***** Running Evaluation *****\n[INFO|trainer.py:3121] 2023-09-02 18:48:35,984 >>   Num examples = 3934\n[INFO|trainer.py:3124] 2023-09-02 18:48:35,986 >>   Batch size = 16\n[INFO|trainer.py:2845] 2023-09-02 18:49:16,214 >> Saving model checkpoint to ./output/checkpoint-1000\n[INFO|configuration_utils.py:460] 2023-09-02 18:49:16,217 >> Configuration saved in ./output/checkpoint-1000/config.json\n[INFO|modeling_utils.py:1953] 2023-09-02 18:49:18,645 >> Model weights saved in ./output/checkpoint-1000/pytorch_model.bin\n[INFO|tokenization_utils_base.py:2235] 2023-09-02 18:49:18,650 >> tokenizer config file saved in ./output/checkpoint-1000/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2242] 2023-09-02 18:49:18,653 >> Special tokens file saved in ./output/checkpoint-1000/special_tokens_map.json\n[INFO|trainer.py:2932] 2023-09-02 18:49:26,596 >> Deleting older checkpoint [output/checkpoint-5000] due to args.save_total_limit\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n[INFO|trainer.py:750] 2023-09-02 18:53:51,508 >> The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: id, text. If id, text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n[INFO|trainer.py:3119] 2023-09-02 18:53:51,516 >> ***** Running Evaluation *****\n[INFO|trainer.py:3121] 2023-09-02 18:53:51,525 >>   Num examples = 3934\n[INFO|trainer.py:3124] 2023-09-02 18:53:51,528 >>   Batch size = 16\n[INFO|trainer.py:2845] 2023-09-02 18:54:31,806 >> Saving model checkpoint to ./output/checkpoint-1500\n[INFO|configuration_utils.py:460] 2023-09-02 18:54:31,810 >> Configuration saved in ./output/checkpoint-1500/config.json\n[INFO|modeling_utils.py:1953] 2023-09-02 18:54:34,328 >> Model weights saved in ./output/checkpoint-1500/pytorch_model.bin\n[INFO|tokenization_utils_base.py:2235] 2023-09-02 18:54:34,335 >> tokenizer config file saved in ./output/checkpoint-1500/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2242] 2023-09-02 18:54:34,337 >> Special tokens file saved in ./output/checkpoint-1500/special_tokens_map.json\n[INFO|trainer.py:2932] 2023-09-02 18:54:42,865 >> Deleting older checkpoint [output/checkpoint-5500] due to args.save_total_limit\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n[INFO|trainer.py:750] 2023-09-02 18:59:07,690 >> The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: id, text. If id, text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n[INFO|trainer.py:3119] 2023-09-02 18:59:07,694 >> ***** Running Evaluation *****\n[INFO|trainer.py:3121] 2023-09-02 18:59:07,696 >>   Num examples = 3934\n[INFO|trainer.py:3124] 2023-09-02 18:59:07,697 >>   Batch size = 16\n[INFO|trainer.py:2845] 2023-09-02 18:59:48,277 >> Saving model checkpoint to ./output/checkpoint-2000\n[INFO|configuration_utils.py:460] 2023-09-02 18:59:48,281 >> Configuration saved in ./output/checkpoint-2000/config.json\n[INFO|modeling_utils.py:1953] 2023-09-02 18:59:50,745 >> Model weights saved in ./output/checkpoint-2000/pytorch_model.bin\n[INFO|tokenization_utils_base.py:2235] 2023-09-02 18:59:50,752 >> tokenizer config file saved in ./output/checkpoint-2000/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2242] 2023-09-02 18:59:50,757 >> Special tokens file saved in ./output/checkpoint-2000/special_tokens_map.json\n[INFO|trainer.py:2932] 2023-09-02 18:59:59,391 >> Deleting older checkpoint [output/checkpoint-500] due to args.save_total_limit\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n[INFO|trainer.py:750] 2023-09-02 19:04:23,817 >> The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: id, text. If id, text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n[INFO|trainer.py:3119] 2023-09-02 19:04:23,821 >> ***** Running Evaluation *****\n[INFO|trainer.py:3121] 2023-09-02 19:04:23,822 >>   Num examples = 3934\n[INFO|trainer.py:3124] 2023-09-02 19:04:23,824 >>   Batch size = 16\n[INFO|trainer.py:2845] 2023-09-02 19:05:04,497 >> Saving model checkpoint to ./output/checkpoint-2500\n[INFO|configuration_utils.py:460] 2023-09-02 19:05:04,501 >> Configuration saved in ./output/checkpoint-2500/config.json\n[INFO|modeling_utils.py:1953] 2023-09-02 19:05:06,907 >> Model weights saved in ./output/checkpoint-2500/pytorch_model.bin\n[INFO|tokenization_utils_base.py:2235] 2023-09-02 19:05:06,914 >> tokenizer config file saved in ./output/checkpoint-2500/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2242] 2023-09-02 19:05:06,919 >> Special tokens file saved in ./output/checkpoint-2500/special_tokens_map.json\n[INFO|trainer.py:2932] 2023-09-02 19:05:15,821 >> Deleting older checkpoint [output/checkpoint-1000] due to args.save_total_limit\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n[INFO|trainer.py:750] 2023-09-02 19:09:40,491 >> The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: id, text. If id, text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n[INFO|trainer.py:3119] 2023-09-02 19:09:40,496 >> ***** Running Evaluation *****\n[INFO|trainer.py:3121] 2023-09-02 19:09:40,497 >>   Num examples = 3934\n[INFO|trainer.py:3124] 2023-09-02 19:09:40,498 >>   Batch size = 16\n[INFO|trainer.py:2845] 2023-09-02 19:10:21,354 >> Saving model checkpoint to ./output/checkpoint-3000\n[INFO|configuration_utils.py:460] 2023-09-02 19:10:21,358 >> Configuration saved in ./output/checkpoint-3000/config.json\n[INFO|modeling_utils.py:1953] 2023-09-02 19:10:23,818 >> Model weights saved in ./output/checkpoint-3000/pytorch_model.bin\n[INFO|tokenization_utils_base.py:2235] 2023-09-02 19:10:23,821 >> tokenizer config file saved in ./output/checkpoint-3000/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2242] 2023-09-02 19:10:23,823 >> Special tokens file saved in ./output/checkpoint-3000/special_tokens_map.json\n[INFO|trainer.py:2932] 2023-09-02 19:10:32,774 >> Deleting older checkpoint [output/checkpoint-1500] due to args.save_total_limit\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n[INFO|trainer.py:750] 2023-09-02 19:14:57,875 >> The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: id, text. If id, text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n[INFO|trainer.py:3119] 2023-09-02 19:14:57,879 >> ***** Running Evaluation *****\n[INFO|trainer.py:3121] 2023-09-02 19:14:57,881 >>   Num examples = 3934\n[INFO|trainer.py:3124] 2023-09-02 19:14:57,882 >>   Batch size = 16\n[INFO|trainer.py:2845] 2023-09-02 19:15:38,449 >> Saving model checkpoint to ./output/checkpoint-3500\n[INFO|configuration_utils.py:460] 2023-09-02 19:15:38,453 >> Configuration saved in ./output/checkpoint-3500/config.json\n[INFO|modeling_utils.py:1953] 2023-09-02 19:15:40,918 >> Model weights saved in ./output/checkpoint-3500/pytorch_model.bin\n[INFO|tokenization_utils_base.py:2235] 2023-09-02 19:15:40,925 >> tokenizer config file saved in ./output/checkpoint-3500/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2242] 2023-09-02 19:15:40,930 >> Special tokens file saved in ./output/checkpoint-3500/special_tokens_map.json\n[INFO|trainer.py:2932] 2023-09-02 19:15:49,415 >> Deleting older checkpoint [output/checkpoint-2000] due to args.save_total_limit\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n[INFO|trainer.py:750] 2023-09-02 19:20:14,531 >> The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: id, text. If id, text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n[INFO|trainer.py:3119] 2023-09-02 19:20:14,536 >> ***** Running Evaluation *****\n[INFO|trainer.py:3121] 2023-09-02 19:20:14,537 >>   Num examples = 3934\n[INFO|trainer.py:3124] 2023-09-02 19:20:14,538 >>   Batch size = 16\n[INFO|trainer.py:2845] 2023-09-02 19:20:55,048 >> Saving model checkpoint to ./output/checkpoint-4000\n[INFO|configuration_utils.py:460] 2023-09-02 19:20:55,052 >> Configuration saved in ./output/checkpoint-4000/config.json\n[INFO|modeling_utils.py:1953] 2023-09-02 19:20:57,527 >> Model weights saved in ./output/checkpoint-4000/pytorch_model.bin\n[INFO|tokenization_utils_base.py:2235] 2023-09-02 19:20:57,531 >> tokenizer config file saved in ./output/checkpoint-4000/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2242] 2023-09-02 19:20:57,539 >> Special tokens file saved in ./output/checkpoint-4000/special_tokens_map.json\n[INFO|trainer.py:2932] 2023-09-02 19:21:06,168 >> Deleting older checkpoint [output/checkpoint-2500] due to args.save_total_limit\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n[INFO|trainer.py:750] 2023-09-02 19:25:31,021 >> The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: id, text. If id, text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n[INFO|trainer.py:3119] 2023-09-02 19:25:31,025 >> ***** Running Evaluation *****\n[INFO|trainer.py:3121] 2023-09-02 19:25:31,026 >>   Num examples = 3934\n[INFO|trainer.py:3124] 2023-09-02 19:25:31,028 >>   Batch size = 16\n[INFO|trainer.py:2845] 2023-09-02 19:26:11,535 >> Saving model checkpoint to ./output/checkpoint-4500\n[INFO|configuration_utils.py:460] 2023-09-02 19:26:11,542 >> Configuration saved in ./output/checkpoint-4500/config.json\n[INFO|modeling_utils.py:1953] 2023-09-02 19:26:14,173 >> Model weights saved in ./output/checkpoint-4500/pytorch_model.bin\n[INFO|tokenization_utils_base.py:2235] 2023-09-02 19:26:14,179 >> tokenizer config file saved in ./output/checkpoint-4500/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2242] 2023-09-02 19:26:14,183 >> Special tokens file saved in ./output/checkpoint-4500/special_tokens_map.json\n[INFO|trainer.py:2932] 2023-09-02 19:26:24,197 >> Deleting older checkpoint [output/checkpoint-3000] due to args.save_total_limit\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n[INFO|trainer.py:750] 2023-09-02 19:30:49,201 >> The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: id, text. If id, text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n[INFO|trainer.py:3119] 2023-09-02 19:30:49,205 >> ***** Running Evaluation *****\n[INFO|trainer.py:3121] 2023-09-02 19:30:49,208 >>   Num examples = 3934\n[INFO|trainer.py:3124] 2023-09-02 19:30:49,210 >>   Batch size = 16\n[INFO|trainer.py:2845] 2023-09-02 19:31:29,889 >> Saving model checkpoint to ./output/checkpoint-5000\n[INFO|configuration_utils.py:460] 2023-09-02 19:31:29,893 >> Configuration saved in ./output/checkpoint-5000/config.json\n[INFO|modeling_utils.py:1953] 2023-09-02 19:31:32,383 >> Model weights saved in ./output/checkpoint-5000/pytorch_model.bin\n[INFO|tokenization_utils_base.py:2235] 2023-09-02 19:31:32,387 >> tokenizer config file saved in ./output/checkpoint-5000/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2242] 2023-09-02 19:31:32,389 >> Special tokens file saved in ./output/checkpoint-5000/special_tokens_map.json\n[INFO|trainer.py:2932] 2023-09-02 19:31:42,430 >> Deleting older checkpoint [output/checkpoint-3500] due to args.save_total_limit\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n[INFO|trainer.py:750] 2023-09-02 19:36:07,135 >> The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: id, text. If id, text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n[INFO|trainer.py:3119] 2023-09-02 19:36:07,139 >> ***** Running Evaluation *****\n[INFO|trainer.py:3121] 2023-09-02 19:36:07,140 >>   Num examples = 3934\n[INFO|trainer.py:3124] 2023-09-02 19:36:07,142 >>   Batch size = 16\n[INFO|trainer.py:2845] 2023-09-02 19:36:47,764 >> Saving model checkpoint to ./output/checkpoint-5500\n[INFO|configuration_utils.py:460] 2023-09-02 19:36:47,768 >> Configuration saved in ./output/checkpoint-5500/config.json\n[INFO|modeling_utils.py:1953] 2023-09-02 19:36:50,215 >> Model weights saved in ./output/checkpoint-5500/pytorch_model.bin\n[INFO|tokenization_utils_base.py:2235] 2023-09-02 19:36:50,222 >> tokenizer config file saved in ./output/checkpoint-5500/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2242] 2023-09-02 19:36:50,230 >> Special tokens file saved in ./output/checkpoint-5500/special_tokens_map.json\n[INFO|trainer.py:2932] 2023-09-02 19:36:59,176 >> Deleting older checkpoint [output/checkpoint-4500] due to args.save_total_limit\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n[INFO|trainer.py:750] 2023-09-02 19:41:23,852 >> The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: id, text. If id, text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n[INFO|trainer.py:3119] 2023-09-02 19:41:23,856 >> ***** Running Evaluation *****\n[INFO|trainer.py:3121] 2023-09-02 19:41:23,857 >>   Num examples = 3934\n[INFO|trainer.py:3124] 2023-09-02 19:41:23,858 >>   Batch size = 16\n[INFO|trainer.py:2845] 2023-09-02 19:42:04,624 >> Saving model checkpoint to ./output/checkpoint-6000\n[INFO|configuration_utils.py:460] 2023-09-02 19:42:04,628 >> Configuration saved in ./output/checkpoint-6000/config.json\n[INFO|modeling_utils.py:1953] 2023-09-02 19:42:07,091 >> Model weights saved in ./output/checkpoint-6000/pytorch_model.bin\n[INFO|tokenization_utils_base.py:2235] 2023-09-02 19:42:07,098 >> tokenizer config file saved in ./output/checkpoint-6000/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2242] 2023-09-02 19:42:07,103 >> Special tokens file saved in ./output/checkpoint-6000/special_tokens_map.json\n[INFO|trainer.py:2932] 2023-09-02 19:42:16,965 >> Deleting older checkpoint [output/checkpoint-4000] due to args.save_total_limit\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n[INFO|trainer.py:750] 2023-09-02 19:46:41,822 >> The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: id, text. If id, text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n[INFO|trainer.py:3119] 2023-09-02 19:46:41,829 >> ***** Running Evaluation *****\n[INFO|trainer.py:3121] 2023-09-02 19:46:41,833 >>   Num examples = 3934\n[INFO|trainer.py:3124] 2023-09-02 19:46:41,837 >>   Batch size = 16\n[INFO|trainer.py:2845] 2023-09-02 19:47:22,520 >> Saving model checkpoint to ./output/checkpoint-6500\n[INFO|configuration_utils.py:460] 2023-09-02 19:47:22,524 >> Configuration saved in ./output/checkpoint-6500/config.json\n[INFO|modeling_utils.py:1953] 2023-09-02 19:47:24,985 >> Model weights saved in ./output/checkpoint-6500/pytorch_model.bin\n[INFO|tokenization_utils_base.py:2235] 2023-09-02 19:47:24,992 >> tokenizer config file saved in ./output/checkpoint-6500/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2242] 2023-09-02 19:47:24,996 >> Special tokens file saved in ./output/checkpoint-6500/special_tokens_map.json\n[INFO|trainer.py:2932] 2023-09-02 19:47:33,741 >> Deleting older checkpoint [output/checkpoint-5000] due to args.save_total_limit\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n[INFO|trainer.py:1962] 2023-09-02 19:48:34,530 >> \n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n[INFO|trainer.py:2124] 2023-09-02 19:48:34,532 >> Loading best model from ./output/checkpoint-6000 (score: 0.8031786680221558).\n","output_type":"stream"}]},{"cell_type":"code","source":"metrics = train_result.metrics\nmax_train_samples = (\n    max_train_samples if max_train_samples is not None else len(train_dataset)\n)\nmetrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))","metadata":{"execution":{"iopub.status.busy":"2023-09-02T19:48:40.520507Z","iopub.execute_input":"2023-09-02T19:48:40.523132Z","iopub.status.idle":"2023-09-02T19:48:40.531542Z","shell.execute_reply.started":"2023-09-02T19:48:40.523091Z","shell.execute_reply":"2023-09-02T19:48:40.530544Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"trainer.save_model()\ntrainer.log_metrics(\"train\", metrics)\ntrainer.save_metrics(\"train\", metrics)\ntrainer.save_state()","metadata":{"execution":{"iopub.status.busy":"2023-09-02T19:48:40.535025Z","iopub.execute_input":"2023-09-02T19:48:40.537729Z","iopub.status.idle":"2023-09-02T19:48:44.048387Z","shell.execute_reply.started":"2023-09-02T19:48:40.537689Z","shell.execute_reply":"2023-09-02T19:48:44.047265Z"},"trusted":true},"execution_count":123,"outputs":[{"name":"stderr","text":"[INFO|trainer.py:2845] 2023-09-02 19:48:40,549 >> Saving model checkpoint to ./output\n[INFO|configuration_utils.py:460] 2023-09-02 19:48:40,553 >> Configuration saved in ./output/config.json\n[INFO|modeling_utils.py:1953] 2023-09-02 19:48:42,882 >> Model weights saved in ./output/pytorch_model.bin\n[INFO|tokenization_utils_base.py:2235] 2023-09-02 19:48:42,889 >> tokenizer config file saved in ./output/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2242] 2023-09-02 19:48:42,893 >> Special tokens file saved in ./output/special_tokens_map.json\n","output_type":"stream"},{"name":"stdout","text":"***** train metrics *****\n  epoch                    =        3.0\n  total_flos               =  6481277GF\n  train_loss               =     0.8605\n  train_runtime            = 1:09:44.44\n  train_samples            =      35266\n  train_samples_per_second =     25.284\n  train_steps_per_second   =      1.581\n","output_type":"stream"}]},{"cell_type":"code","source":"logger.info(\"*** Evaluate ***\")\n\nmetrics = trainer.evaluate(eval_dataset=eval_dataset)\n\nmax_eval_samples = (\n    max_eval_samples if max_eval_samples is not None else len(eval_dataset)\n)\nmetrics[\"eval_samples\"] = min(max_eval_samples, len(eval_dataset))\n\ntrainer.log_metrics(\"eval\", metrics)\ntrainer.save_metrics(\"eval\", metrics)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T19:48:44.053199Z","iopub.execute_input":"2023-09-02T19:48:44.055790Z","iopub.status.idle":"2023-09-02T19:49:24.881192Z","shell.execute_reply.started":"2023-09-02T19:48:44.055731Z","shell.execute_reply":"2023-09-02T19:49:24.880247Z"},"trusted":true},"execution_count":124,"outputs":[{"name":"stderr","text":"[INFO|trainer.py:750] 2023-09-02 19:48:44,062 >> The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: id, text. If id, text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n[INFO|trainer.py:3119] 2023-09-02 19:48:44,069 >> ***** Running Evaluation *****\n[INFO|trainer.py:3121] 2023-09-02 19:48:44,072 >>   Num examples = 3934\n[INFO|trainer.py:3124] 2023-09-02 19:48:44,075 >>   Batch size = 16\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"***** eval metrics *****\n  epoch                   =        3.0\n  eval_accuracy           =     0.6579\n  eval_loss               =     0.8032\n  eval_micro_f1_score     =     0.6579\n  eval_runtime            = 0:00:40.78\n  eval_samples            =       3934\n  eval_samples_per_second =     96.465\n  eval_steps_per_second   =      6.032\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\npredictions = trainer.predict(predict_dataset).predictions\npredicted_labels = predictions.argmax(axis=1)\nactual_labels = predict_dataset['label']\naccuracy = accuracy_score(actual_labels, predicted_labels)\nprint(\"Test Accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T19:57:38.091352Z","iopub.execute_input":"2023-09-02T19:57:38.091791Z","iopub.status.idle":"2023-09-02T19:58:47.965364Z","shell.execute_reply.started":"2023-09-02T19:57:38.091759Z","shell.execute_reply":"2023-09-02T19:58:47.964344Z"},"trusted":true},"execution_count":128,"outputs":[{"name":"stderr","text":"[INFO|trainer.py:750] 2023-09-02 19:57:38,096 >> The following columns in the test set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: id, text. If id, text are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n[INFO|trainer.py:3119] 2023-09-02 19:57:38,101 >> ***** Running Prediction *****\n[INFO|trainer.py:3121] 2023-09-02 19:57:38,103 >>   Num examples = 6707\n[INFO|trainer.py:3124] 2023-09-02 19:57:38,105 >>   Batch size = 16\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 0.6560310123751305\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n\n\ntrue_labels = predict_dataset[\"label\"]\n\n\nclassification_rep = classification_report(true_labels, predicted_labels, target_names=[\"Class 0\", \"Class 1\", \"Class 2\"])\nprint(\"Classification Report:\\n\", classification_rep)\n\nmacro_f1 = f1_score(true_labels, predicted_labels, average=\"macro\")\nmicro_f1 = f1_score(true_labels, predicted_labels, average=\"micro\")\nprint(f\"Macro F1 Score: {macro_f1}\")\nprint(f\"Micro F1 Score: {micro_f1}\")\n\nprecision = precision_score(true_labels, predicted_labels, average=\"weighted\")  # For binary classification\nrecall = recall_score(true_labels, predicted_labels, average=\"weighted\")  # For binary classification\nprint(f\"Precision: {precision}\")\nprint(f\"Recall: {recall}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-02T20:36:20.250799Z","iopub.execute_input":"2023-09-02T20:36:20.251591Z","iopub.status.idle":"2023-09-02T20:36:20.335012Z","shell.execute_reply.started":"2023-09-02T20:36:20.251556Z","shell.execute_reply":"2023-09-02T20:36:20.333992Z"},"trusted":true},"execution_count":133,"outputs":[{"name":"stdout","text":"Classification Report:\n               precision    recall  f1-score   support\n\n     Class 0       0.71      0.76      0.73      3338\n     Class 1       0.51      0.26      0.34      1277\n     Class 2       0.62      0.74      0.67      2092\n\n    accuracy                           0.66      6707\n   macro avg       0.61      0.58      0.58      6707\nweighted avg       0.64      0.66      0.64      6707\n\nMacro F1 Score: 0.5830182507501224\nMicro F1 Score: 0.6560310123751305\nPrecision: 0.6427435080949613\nRecall: 0.6560310123751305\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nconfusion = confusion_matrix(actual_labels, predicted_labels)\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(confusion, annot=True, fmt='d', cmap='Blues', xticklabels=True, yticklabels=True)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-02T19:58:47.970920Z","iopub.execute_input":"2023-09-02T19:58:47.973544Z","iopub.status.idle":"2023-09-02T19:58:48.300868Z","shell.execute_reply.started":"2023-09-02T19:58:47.973502Z","shell.execute_reply":"2023-09-02T19:58:48.299798Z"},"trusted":true},"execution_count":129,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}